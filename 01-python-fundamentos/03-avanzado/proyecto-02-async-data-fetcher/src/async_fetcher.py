"""
Async Data Fetcher - Descarga de Datos As√≠ncrona
================================================

Demuestra programaci√≥n as√≠ncrona con asyncio y aiohttp para:
- Descargar m√∫ltiples URLs en paralelo
- Procesar datos de forma as√≠ncrona
- Manejo de concurrencia
- Rate limiting as√≠ncrono
"""

import asyncio
import aiohttp
import time
from typing import List, Dict
import json

async def fetch_url(session: aiohttp.ClientSession, url: str, semaphore: asyncio.Semaphore) -> Dict:
    """
    Descarga una URL de forma as√≠ncrona.
    
    Args:
        session: Sesi√≥n aiohttp
        url: URL a descargar
        semaphore: Sem√°foro para limitar concurrencia
    """
    async with semaphore:
        try:
            print(f"üì° Descargando: {url}")
            async with session.get(url) as response:
                data = await response.json()
                print(f"   ‚úÖ Completado: {url}")
                return {'url': url, 'status': response.status, 'data': data}
        except Exception as e:
            print(f"   ‚ùå Error en {url}: {e}")
            return {'url': url, 'status': 'error', 'error': str(e)}


async def fetch_multiple_urls(urls: List[str], max_concurrent: int = 5) -> List[Dict]:
    """
    Descarga m√∫ltiples URLs en paralelo con l√≠mite de concurrencia.
    
    Args:
        urls: Lista de URLs
        max_concurrent: M√°ximo de descargas simult√°neas
    """
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url(session, url, semaphore) for url in urls]
        results = await asyncio.gather(*tasks)
    
    return results


async def process_data_async(data_list: List[Dict]) -> List[Dict]:
    """Procesa datos de forma as√≠ncrona."""
    async def process_item(item: Dict) -> Dict:
        # Simular procesamiento
        await asyncio.sleep(0.1)
        if 'data' in item:
            item['processed'] = True
        return item
    
    tasks = [process_item(item) for item in data_list]
    return await asyncio.gather(*tasks)


async def ejemplo_basico():
    """Ejemplo b√°sico de async/await."""
    print("\n" + "="*70)
    print("üöÄ EJEMPLO: ASYNC/AWAIT B√ÅSICO")
    print("="*70)
    
    # API p√∫blica de ejemplo
    urls = [
        'https://jsonplaceholder.typicode.com/posts/1',
        'https://jsonplaceholder.typicode.com/posts/2',
        'https://jsonplaceholder.typicode.com/posts/3',
        'https://jsonplaceholder.typicode.com/posts/4',
        'https://jsonplaceholder.typicode.com/posts/5',
    ]
    
    # Sync vs Async comparison
    print("\n‚è±Ô∏è  Comparando velocidad...")
    
    # Async
    start = time.time()
    results = await fetch_multiple_urls(urls, max_concurrent=5)
    async_time = time.time() - start
    
    print(f"\nüìä Resultados:")
    print(f"   URLs procesadas: {len(results)}")
    print(f"   Exitosas: {sum(1 for r in results if r.get('status') == 200)}")
    print(f"   Tiempo async: {async_time:.2f}s")
    print(f"   üöÄ Las peticiones se hicieron en paralelo!")


async def ejemplo_rate_limiting():
    """Ejemplo con rate limiting."""
    print("\n" + "="*70)
    print("‚è±Ô∏è  EJEMPLO: RATE LIMITING")
    print("="*70)
    
    urls = [f'https://jsonplaceholder.typicode.com/posts/{i}' for i in range(1, 11)]
    
    print(f"\nDescargando {len(urls)} URLs con max 3 concurrent...")
    start = time.time()
    results = await fetch_multiple_urls(urls, max_concurrent=3)
    duration = time.time() - start
    
    print(f"\n‚úÖ Completado en {duration:.2f}s")
    print(f"   Promedio: {duration/len(urls):.2f}s por URL")


async def ejemplo_procesamiento_pipeline():
    """Ejemplo de pipeline de procesamiento as√≠ncrono."""
    print("\n" + "="*70)
    print("üîÑ EJEMPLO: PIPELINE AS√çNCRONO")
    print("="*70)
    
    # 1. Fetch
    urls = [f'https://jsonplaceholder.typicode.com/users/{i}' for i in range(1, 6)]
    print("\n1Ô∏è‚É£ Fetching data...")
    data = await fetch_multiple_urls(urls, max_concurrent=5)
    
    # 2. Process
    print("\n2Ô∏è‚É£ Processing data...")
    processed = await process_data_async(data)
    
    # 3. Results
    print(f"\n‚úÖ Pipeline completado:")
    print(f"   Items procesados: {len(processed)}")
    successful = [p for p in processed if p.get('processed')]
    print(f"   Exitosos: {len(successful)}")


def main():
    """Funci√≥n principal."""
    print("="*70)
    print("‚ö° ASYNC DATA FETCHER")
    print("="*70)
    
    # Ejecutar ejemplos
    asyncio.run(ejemplo_basico())
    asyncio.run(ejemplo_rate_limiting())
    asyncio.run(ejemplo_procesamiento_pipeline())
    
    print("\n" + "="*70)
    print("‚ú® EJEMPLOS COMPLETADOS")
    print("="*70)
    print("\nüí° Programaci√≥n as√≠ncrona permite:")
    print("   - Descargas paralelas eficientes")
    print("   - Mejor uso de recursos")
    print("   - Rate limiting controlado")
    print("   - Pipelines de datos escalables")


if __name__ == "__main__":
    main()
